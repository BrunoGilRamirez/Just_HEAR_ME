{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T20:11:29.413575Z",
     "iopub.status.busy": "2024-08-05T20:11:29.413345Z",
     "iopub.status.idle": "2024-08-05T20:12:24.756159Z",
     "shell.execute_reply": "2024-08-05T20:12:24.755518Z",
     "shell.execute_reply.started": "2024-08-05T20:11:29.413556Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers==4.43.3\n",
    "#!pip install -U git+https://github.com/huggingface/transformers\n",
    "!pip install -U accelerate==0.33.0\n",
    "!pip install -U torch==2.1.1\n",
    "!pip install datasets==2.20.0\n",
    "#!pip install -U trl\n",
    "!pip install git+https://github.com/huggingface/trl.git\n",
    "!pip install -q -U bitsandbytes==0.43.3 einops==0.8.0 wandb\n",
    "!pip install -U huggingface-hub==0.24.5\n",
    "# peft es una libreria para calcular la eficiencia de la aceleración de un modelo\n",
    "!pip install -U tokenizers==0.19.1\n",
    "!pip install -U peft==0.12.0\n",
    "!pip install load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:19:42.988644Z",
     "iopub.status.busy": "2024-08-05T21:19:42.988070Z",
     "iopub.status.idle": "2024-08-05T21:19:44.532802Z",
     "shell.execute_reply": "2024-08-05T21:19:44.532360Z",
     "shell.execute_reply.started": "2024-08-05T21:19:42.988617Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "# Load model directly\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    ")\n",
    "import torch, load_dotenv, os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from huggingface_hub import login # huggingface_hub es de hugingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:19:45.266088Z",
     "iopub.status.busy": "2024-08-05T21:19:45.265515Z",
     "iopub.status.idle": "2024-08-05T21:19:45.352281Z",
     "shell.execute_reply": "2024-08-05T21:19:45.351894Z",
     "shell.execute_reply.started": "2024-08-05T21:19:45.266064Z"
    }
   },
   "outputs": [],
   "source": [
    "if load_dotenv.load_dotenv('../env.env'):\n",
    "    access_token = os.getenv('acesstoken' )\n",
    "    login(token=access_token, add_to_git_credential=True)\n",
    "    print(\"authenticated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:22:38.463559Z",
     "iopub.status.busy": "2024-08-05T21:22:38.462981Z",
     "iopub.status.idle": "2024-08-05T21:22:44.334217Z",
     "shell.execute_reply": "2024-08-05T21:22:44.333802Z",
     "shell.execute_reply.started": "2024-08-05T21:22:38.463530Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"BrunoGR/Just_HEAR_Me\",\n",
    "    torch_dtype=torch.float16,\n",
    "    #quantization_config=bnb_config,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:20:10.880837Z",
     "iopub.status.busy": "2024-08-05T21:20:10.879958Z",
     "iopub.status.idle": "2024-08-05T21:20:11.164658Z",
     "shell.execute_reply": "2024-08-05T21:20:11.164040Z",
     "shell.execute_reply.started": "2024-08-05T21:20:10.880809Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"BrunoGR/Just_HEAR_Me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:20:14.439877Z",
     "iopub.status.busy": "2024-08-05T21:20:14.439322Z",
     "iopub.status.idle": "2024-08-05T21:20:14.445780Z",
     "shell.execute_reply": "2024-08-05T21:20:14.445180Z",
     "shell.execute_reply.started": "2024-08-05T21:20:14.439853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configurar la interfaz de usuario\n",
    "input_box = widgets.Text(\n",
    "    placeholder='Escribe tu mensaje aquí...',\n",
    "    description='Mensaje:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def respond_to_message(message:str,prev:str=\"\",temperature=0.7, top_k=50, top_p=0.9, num_beams=5):\n",
    "    # Tokenizar el mensaje de entrada\n",
    "    prompt= '''### instruction: \n",
    "    You are an emotional assistant, respond empathetically in Spanish to each of the messages. If the user seems sad or upset, you should offer words of encouragement. If the user seems happy or excited, the assistant should share that joy and respond enthusiastically. In all cases, the assistant should maintain a respectful tone, if possible, encouraging you to talk more about it. Don't say hello, unless necessary. Use the username and pronoun to respond in a personalized way. \n",
    "    ### input:'''\n",
    "    message= prompt+prev+\"User:\\n\"+ message+\"\\nemotional assistant(response in spanish):\"\n",
    "    input_ids = tokenizer.encode(message + tokenizer.eos_token, return_tensors='pt')\n",
    "    input_ids = input_ids.to('cuda')\n",
    "\n",
    "    # Generar la respuesta del modelo\n",
    "    chat_history_ids = model.generate(input_ids, \n",
    "                                      max_length=4000,\n",
    "                                      num_beams=num_beams,\n",
    "                                      temperature=temperature,\n",
    "                                      top_k=top_k,\n",
    "                                      top_p=top_p,\n",
    "                                     early_stopping=True)\n",
    "\n",
    "    # Decodificar la respuesta\n",
    "    response = tokenizer.decode(chat_history_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "\n",
    "    return response\n",
    "\n",
    "def on_message_submit(user_message:str, prev:str =\"\",temperature=0.7, top_k=50, top_p=0.9, num_beams=5):\n",
    "    \n",
    "    response = respond_to_message(user_message, prev, temperature, top_k, top_p, num_beams)\n",
    "    conversation= f\"{prev}User: {user_message}\\nemotional assistant: {response}\\n\"\n",
    "    return conversation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:23:12.632253Z",
     "iopub.status.busy": "2024-08-05T21:23:12.631527Z",
     "iopub.status.idle": "2024-08-05T21:23:12.634478Z",
     "shell.execute_reply": "2024-08-05T21:23:12.634092Z",
     "shell.execute_reply.started": "2024-08-05T21:23:12.632232Z"
    }
   },
   "outputs": [],
   "source": [
    "prev=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:20:24.269176Z",
     "iopub.status.busy": "2024-08-05T21:20:24.268478Z",
     "iopub.status.idle": "2024-08-05T21:20:24.271780Z",
     "shell.execute_reply": "2024-08-05T21:20:24.271294Z",
     "shell.execute_reply.started": "2024-08-05T21:20:24.269121Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_s='''User: Hola!\n",
    "emotional assistant: \n",
    "Hola, ¿cómo estás hoy? ¿Hay algo en lo que pueda ayudarte?\n",
    "User: Estoy muy bien y tu?\n",
    "emotional assistant: \n",
    "Me alegra saber que estás bien. ¿Hay algo en lo que pueda ayudarte? Estoy aquí para escucharte.\n",
    "User: Pues hoy tuve un buen dia, quieres escucharlo?\n",
    "emotional assistant: \n",
    "Me alegra mucho que hayas tenido un buen día. Cuéntame más sobre lo que sucedió.\n",
    "User: Pues mira, te cuento que hoy en mi trabajo me dijeron que las cosas se estan poniendo interesantes, aun mas con el proyecto que estoy desarrollando, porque a unos proveedores les intereso, hoy agendaron una cita.\n",
    "emotional assistant: \n",
    "¡Eso suena emocionante! Es genial cuando las cosas se ponen interesantes en el trabajo. ¿Cómo te sientes al respecto?\n",
    "User: Pues bastante emocionado, pero nervioso a la vez, no se como decirlo, pero tengo miedo a fallar y que cancelen todo el proyecto.\n",
    "emotional assistant: \n",
    "Comprendo tu nerviosismo, pero recuerda que todos cometemos errores y lo importante es aprender de ellos. Confía en tus habilidades y en el proyecto que estás desarrollando. Estoy aquí para apoyarte en lo que necesites.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:20:26.847315Z",
     "iopub.status.busy": "2024-08-05T21:20:26.846516Z",
     "iopub.status.idle": "2024-08-05T21:20:26.850374Z",
     "shell.execute_reply": "2024-08-05T21:20:26.849715Z",
     "shell.execute_reply.started": "2024-08-05T21:20:26.847291Z"
    }
   },
   "outputs": [],
   "source": [
    "prev_a='''User: Este fin de semana que estuve con mis amigos, me di cuenta de algo muy incomodo, pero si te soy sincero no se como actuar al respecto. Me di cuenta que mi amigo Alex, le esta hablando a mi ex pareja, yo creo que el no se dio cuenta, perocuando se me acerco para platicar, en su telefono aparecio una notificacion de un mensaje con la foto de perfil de mi ex.no supe que decir, y mejor me calle. No se como decirle que es incomodo que hable con mi ex.\n",
    "emotional assistant: \n",
    "Lamento que hayas tenido esa experiencia incómoda con tu amigo y tu ex pareja. A veces, las situaciones pueden ser difíciles de manejar. ¿Quieres hablar más sobre cómo te sientes al respecto?\n",
    "User: Alex y mi ex, siempre se llevaron bien. No se como decirlo, pero con otros amigos mi ex era mas reservada. Cuando eran fiestas o reuniones no se despegaba de mi, pero si estaba Alex, pues ella podia quedarse platicando horas. Eso antes no me molestaba, pues eran amigos nada mas. pero ahora no se que este pasando entre ellos. Algo me dice que ella siempre estuvo atraida por Alex y el hacia ella.\n",
    "emotional assistant: \n",
    "Lamento que hayas tenido esa experiencia incómoda con tu amigo y tu ex pareja. A veces, las situaciones pueden ser difíciles de manejar. ¿Quieres hablar más sobre cómo te sientes al respecto?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:27:55.363413Z",
     "iopub.status.busy": "2024-08-05T21:27:55.363191Z",
     "iopub.status.idle": "2024-08-05T21:28:07.686820Z",
     "shell.execute_reply": "2024-08-05T21:28:07.686352Z",
     "shell.execute_reply.started": "2024-08-05T21:27:55.363397Z"
    }
   },
   "outputs": [],
   "source": [
    "temperature=.79999999\n",
    "top_k=70\n",
    "top_p=.0002333333\n",
    "num_beams=5\n",
    "message='''Message here'''\n",
    "prev=on_message_submit(message,\n",
    "                       prev,\n",
    "                       #prev,\n",
    "                       temperature, \n",
    "                       top_k, \n",
    "                       top_p, \n",
    "                       num_beams)\n",
    "print(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T21:28:17.006287Z",
     "iopub.status.busy": "2024-08-05T21:28:17.005843Z",
     "iopub.status.idle": "2024-08-05T21:28:17.011112Z",
     "shell.execute_reply": "2024-08-05T21:28:17.010647Z",
     "shell.execute_reply.started": "2024-08-05T21:28:17.006267Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tokenizer.tokenize(prev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
