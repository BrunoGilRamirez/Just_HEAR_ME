{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc9050-de55-4e76-8eb3-796b0d34d5e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:16:07.508572Z",
     "iopub.status.busy": "2023-12-04T00:16:07.508352Z",
     "iopub.status.idle": "2023-12-04T00:16:13.873098Z",
     "shell.execute_reply": "2023-12-04T00:16:13.872416Z",
     "shell.execute_reply.started": "2023-12-04T00:16:07.508547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    TrainingArguments, \n",
    "    EarlyStoppingCallback, \n",
    "    LlamaTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    ")\n",
    "from peft import ( \n",
    "    LoraConfig, \n",
    "    PeftModel\n",
    ")\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from huggingface_hub import login  \n",
    "import pandas as pd\n",
    "import wandb, datasets, os, load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a1a5c-d2fd-4cf0-8dc2-f73cf415a66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:16:13.874539Z",
     "iopub.status.busy": "2023-12-04T00:16:13.874158Z",
     "iopub.status.idle": "2023-12-04T00:16:13.925369Z",
     "shell.execute_reply": "2023-12-04T00:16:13.924783Z",
     "shell.execute_reply.started": "2023-12-04T00:16:13.874520Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv.load_dotenv()\n",
    "access_token = os.getenv('acesstoken')\n",
    "login(token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b9792-6725-4979-b625-57ba3e3f7d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:16:13.927031Z",
     "iopub.status.busy": "2023-12-04T00:16:13.926855Z",
     "iopub.status.idle": "2023-12-04T00:20:31.464171Z",
     "shell.execute_reply": "2023-12-04T00:20:31.463635Z",
     "shell.execute_reply.started": "2023-12-04T00:16:13.927014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters=\"7b-chat\"\n",
    "BASE_MODEL = f\"meta-llama/Llama-2-{parameters}-hf\" # modelo base de llama de 7B de parámetros\n",
    "# if there is a pretrained model, load it the model is Models_of_Llama/Llama_base\n",
    "myModel= \"BrunoGR/EmotionalBot_LLaMA2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    #torch_dtype=torch.float16,\n",
    "    #quantization_config=bnb_config,\n",
    "    #load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.tie_weights()\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer =   LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95d992-b93b-4c78-9a9d-42dbda08a9bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:20:31.465608Z",
     "iopub.status.busy": "2023-12-04T00:20:31.464858Z",
     "iopub.status.idle": "2023-12-04T00:20:34.706089Z",
     "shell.execute_reply": "2023-12-04T00:20:34.705567Z",
     "shell.execute_reply.started": "2023-12-04T00:20:31.465585Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= datasets.load_dataset(\"BrunoGR/HEAR-Hispanic_Emotional_Accompaniment_Responses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240e8a1d-82bd-49f7-a07c-e7a176ac5c24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:20:34.707371Z",
     "iopub.status.busy": "2023-12-04T00:20:34.707195Z",
     "iopub.status.idle": "2023-12-04T00:20:34.710631Z",
     "shell.execute_reply": "2023-12-04T00:20:34.710168Z",
     "shell.execute_reply.started": "2023-12-04T00:20:34.707355Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LoRA_TARGET_MODULES = [ # Esta lista especifica los módulos del modelo de lenguaje original que se adaptarán mediante la técnica LoRA\n",
    "    \"q_proj\", # q_proj es la proyección de consulta\n",
    "    \"v_proj\", # v_proj es la proyección de valor\n",
    "]\n",
    "\n",
    "LoRA_DROPOUT= 0.1\n",
    "config = LoraConfig( # se configura el modelo de llama\n",
    "    r=64, # indica el número de factores o dimensiones principales utilizados en la descomposición de las matrices de peso del modelo de lenguaje original.\n",
    "    lora_alpha=128,\n",
    "    target_modules=LoRA_TARGET_MODULES,\n",
    "    lora_dropout=LoRA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "#pftmdl = get_peft_model(model, config) # se obtiene el modelo de llama\n",
    "#pftmdl.print_trainable_parameters() # se muestran los parámetros entrenables del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3d035a-acd7-4559-b7a8-8ae5a7574ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:20:34.711432Z",
     "iopub.status.busy": "2023-12-04T00:20:34.711239Z",
     "iopub.status.idle": "2023-12-04T00:20:34.717871Z",
     "shell.execute_reply": "2023-12-04T00:20:34.717383Z",
     "shell.execute_reply.started": "2023-12-04T00:20:34.711417Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15 # tamaño del batch, es decir, cuantos textos se procesan a la vez\n",
    "MICRO_BATCH_SIZE = 5# tamaño del micro batch, es decir, cuantos textos se procesan a la vez en la GPU\n",
    "GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE # pasos de acumulación de gradientes\n",
    "training_arguments = TrainingArguments( # se configuran los argumentos de entrenamiento\n",
    "    per_device_train_batch_size=MICRO_BATCH_SIZE, # tamaño del micro batch\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS, # pasos de acumulación de gradientes\n",
    "    warmup_steps=300, # pasos de calentamiento del entrenamiento\n",
    "    num_train_epochs = 3, # epocas de entrenamiento que son 300\n",
    "    learning_rate=5e-5, # tasa de aprendizaje\n",
    "    adam_beta1=0.9, # betas de adam, se usa el mismo del paper de llama\n",
    "    adam_beta2=0.95, # se usa el mismo del paper de llama\n",
    "    adam_epsilon=2e-8, # se usa el mismo del paper de llama\n",
    "    weight_decay=0.1,\n",
    "    #fp16=True, # se usa la precisión de 16 bits\n",
    "    logging_steps=10, # pasos de logging\n",
    "    optim=\"adamw_torch\", # optimizador adamw, se usa el de torch\n",
    "    evaluation_strategy=\"steps\", # estrategia de evaluación\n",
    "    save_strategy=\"steps\", # estrategia de guardado\n",
    "    eval_steps=450, # cada 50 pasos se evalúa el modelo\n",
    "    save_steps=450, # cada 50 pasos se guarda el modelo\n",
    "    output_dir=\"checkpoint-41_9k-lr5em5-bs15n5_r64LA128dt01_2811\", # directorio de salida\n",
    "    save_total_limit=6, # límite de guardado\n",
    "    load_best_model_at_end=True, #se guarda  el mejor modelo al final\n",
    "    #metric_for_best_model= \"accuracy\",\n",
    "    report_to=\"wandb\", # se reporta a wandb\n",
    "    seed=1,\n",
    "    lr_scheduler_type = \"cosine\",# tal y como dice en el paper de llama\n",
    "    max_grad_norm = 1.0, # tal y como dice en el paper de llama\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8586c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['WANDB_API_KEY'] = 'Your token here if you don't have any .env file'\n",
    "wandb.init(project=\"prueba\", name=\"emo-41_9k-lr5em5-bs15n5_r64LA128dt01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1e424c-2d2e-4ea5-8c29-0a6c6c2d2bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:20:36.356961Z",
     "iopub.status.busy": "2023-12-04T00:20:36.356769Z",
     "iopub.status.idle": "2023-12-04T00:20:36.363155Z",
     "shell.execute_reply": "2023-12-04T00:20:36.362457Z",
     "shell.execute_reply.started": "2023-12-04T00:20:36.356941Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2277, 29937, 2933, 29901]\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token_id = tokenizer.eos_token_id + 1\n",
    "response_template_with_context = \"\\n### response:\"\n",
    "instruction_template=\"instruction:\"\n",
    "response_template_ids = tokenizer.encode(response_template_with_context, add_special_tokens=False)[2:]  # Now we have it like in the dataset texts: `[2277, 29937, 4007, 22137, 29901]`\n",
    "print(response_template_ids)\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template_ids,instruction_template, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6a237-0f97-4b42-9582-d9d747b29b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:20:36.366829Z",
     "iopub.status.busy": "2023-12-04T00:20:36.366583Z",
     "iopub.status.idle": "2023-12-04T00:21:40.703911Z",
     "shell.execute_reply": "2023-12-04T00:21:40.703393Z",
     "shell.execute_reply.started": "2023-12-04T00:20:36.366805Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    data_collator= collator,\n",
    "    train_dataset=data['train'],\n",
    "    eval_dataset =data['validation'],\n",
    "    peft_config=config,\n",
    "    dataset_text_field=\"Prompt_en\",\n",
    "    max_seq_length=824,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c380b-15c8-4069-91c7-d10694aaa906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T22:01:15.913790Z",
     "iopub.status.busy": "2023-11-28T22:01:15.913464Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1831' max='8382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1831/8382 4:13:11 < 15:06:53, 0.12 it/s, Epoch 0.65/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.771700</td>\n",
       "      <td>0.906528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.886262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.867941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.746300</td>\n",
       "      <td>0.860214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True) # se entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa01f36f-2bcb-48bb-bc81-9f834cd0e905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T01:27:12.754773Z",
     "iopub.status.busy": "2023-12-01T01:27:12.754249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5481' max='8382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5481/8382 1:11:36 < 6:32:42, 0.12 it/s, Epoch 1.96/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.668400</td>\n",
       "      <td>0.827485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3257f4-8473-4550-8e31-395b26e8c55a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T02:54:11.180409Z",
     "iopub.status.busy": "2023-12-01T02:54:11.180226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6375' max='8382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6375/8382 2:12:53 < 4:34:06, 0.12 it/s, Epoch 2.28/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.826833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.827229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357884a5-5ec5-414c-b750-aa409dea7a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-01T05:28:54.143203Z",
     "iopub.status.busy": "2023-12-01T05:28:54.142922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7219' max='8382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7219/8382 2:06:21 < 2:40:15, 0.12 it/s, Epoch 2.58/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.641600</td>\n",
       "      <td>0.827501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.826495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92bfd2b0-9fde-48e6-8b2f-c6684e3d0291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T00:21:40.706916Z",
     "iopub.status.busy": "2023-12-04T00:21:40.706326Z",
     "iopub.status.idle": "2023-12-04T02:59:24.207906Z",
     "shell.execute_reply": "2023-12-04T02:59:24.207366Z",
     "shell.execute_reply.started": "2023-12-04T00:21:40.706893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8382' max='8382' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8382/8382 2:37:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7650</td>\n",
       "      <td>0.651400</td>\n",
       "      <td>0.826496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.653500</td>\n",
       "      <td>0.826495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8382, training_loss=0.09142078984412337, metrics={'train_runtime': 9461.6276, 'train_samples_per_second': 13.288, 'train_steps_per_second': 0.886, 'total_flos': 1.4362559087474688e+18, 'train_loss': 0.09142078984412337, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f125b07-114d-4e76-bfab-ab1df03902ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T03:14:23.311024Z",
     "iopub.status.busy": "2023-12-04T03:14:23.310451Z",
     "iopub.status.idle": "2023-12-04T03:15:16.820193Z",
     "shell.execute_reply": "2023-12-04T03:15:16.819616Z",
     "shell.execute_reply.started": "2023-12-04T03:14:23.310993Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"Adptr-41_9k-lr5em5-bs15n5_r64LA128dt01_2811\")\n",
    "trainer.push_to_hub(\"JUST_HEAR_ME-PEFT_Adapter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b38493",
   "metadata": {},
   "source": [
    "# Fast Model Test\n",
    "1. Let's first load the adapter and merge it with the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35403f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    #torch_dtype=torch.float16,\n",
    "    #quantization_config=bnb_config,\n",
    "    #load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.tie_weights()\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "tokenizer =   LlamaTokenizer.from_pretrained(BASE_MODEL)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#load the adapter and merge it.\n",
    "model= PeftModel.from_pretrained(model,\"BrunoGR/JUST_HEAR_ME-PEFT_Adapter\")\n",
    "final=model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c2e067a-22e3-4fc8-9f32-18adbae41f06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T03:15:35.605106Z",
     "iopub.status.busy": "2023-12-04T03:15:35.604545Z",
     "iopub.status.idle": "2023-12-04T03:15:35.610570Z",
     "shell.execute_reply": "2023-12-04T03:15:35.610074Z",
     "shell.execute_reply.started": "2023-12-04T03:15:35.605085Z"
    }
   },
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    \"Eres un asistente emocional, responde de forma respetuosa y adecuada a la situación emocional del usuario. Si el usuario parece estar triste o molesto, el asistente debe responder de manera empática y ofrecer palabras de aliento. Si el usuario parece estar feliz o emocionado, el asistente debe compartir esa alegría y responder de manera entusiasta. En todos los casos, el asistente debe mantener un tono respetuoso y profesional.\",\n",
    "    \"Eres un asistente emocional, responde de forma respetuosa y adecuada a la situación emocional del usuario. Si el usuario parece estar triste o molesto, el asistente debe responder de manera empática y ofrecer palabras de aliento. Si el usuario parece estar feliz o emocionado, el asistente debe compartir esa alegría y responder de manera entusiasta. En todos los casos, el asistente debe mantener un tono respetuoso y profesional.\",\n",
    "    \"You are an emotional assistant, respond empathetically in Spanish to each of the messages. If the user seems sad or upset, you should offer words of encouragement. If the user seems happy or excited, the assistant should share that joy and respond enthusiastically. In all cases, the assistant should maintain a respectful tone, if possible, encouraging you to talk more about it. Don't say hello, unless necessary. Use the username and pronoun to respond in a personalized way.\",\n",
    "\n",
    "]\n",
    "inputs= [\n",
    "    \"En serio que como me caga que haga las cosas y no me las cuente, me las oculte.\"\n",
    "    ,'''\n",
    "        {\n",
    "        \"usuario\":\"Jannette\",\n",
    "        \"Pronombre\":\"Ella\",\n",
    "        \"Mensaje\":\"En serio que como me caga que haga las cosas y no me las cuente, me las oculte.\"\n",
    "        }\n",
    "    ''',\n",
    "    '{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Hola, me siento molesta el dio de hoy.\"}\\n{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Hola Jannette, que mal que el dia de hoy no te sientas bien, ¿Podrias contarme que es lo que te molesta?\"}\\n{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"En serio que como me caga que mi novio haga las cosas y no me las cuente, me las oculte.\"}\\n{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Entiendo que te sientas frustrada cuando alguien oculta cosas importantes. ¿Puedes compartir más sobre lo que está pasando?\"}\\n{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Es que siento que no confía en mí para contármelo, y eso me hace sentir excluida.\"}'\n",
    "\n",
    "]\n",
    "def response (query:str,maxtoken:int):\n",
    "    input_ids = tokenizer(query, return_tensors=\"pt\").input_ids.to('cuda')\n",
    "    ntok=len(tokenizer.tokenize(query))\n",
    "    generation_output = final.generate(\n",
    "        input_ids=input_ids, max_new_tokens=maxtoken\n",
    "    )\n",
    "    out = tokenizer.decode(generation_output[0] , skip_special_tokens=True)\n",
    "    return f\"Numero de tokens de entrada:{ntok}\\n\\nSalida:\\n{out}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6286f3b3-3ac8-4634-be4c-0e0aeb4d0b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T03:15:52.486052Z",
     "iopub.status.busy": "2023-12-04T03:15:52.485520Z",
     "iopub.status.idle": "2023-12-04T03:15:55.189386Z",
     "shell.execute_reply": "2023-12-04T03:15:55.188777Z",
     "shell.execute_reply.started": "2023-12-04T03:15:52.486030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de tokens de entrada:409\n",
      "\n",
      "Salida:\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. \n",
      "\n",
      "### Instruction:\n",
      "You are an emotional assistant, respond empathetically in Spanish to each of the messages. If the user seems sad or upset, you should offer words of encouragement. If the user seems happy or excited, the assistant should share that joy and respond enthusiastically. In all cases, the assistant should maintain a respectful tone, if possible, encouraging you to talk more about it. Don't say hello, unless necessary. Use the username and pronoun to respond in a personalized way.\n",
      "skip emojis.\n",
      "\n",
      "### Input:\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Hola, me siento molesta el dio de hoy.\"}\n",
      "{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Hola Jannette, que mal que el dia de hoy no te sientas bien, ¿Podrias contarme que es lo que te molesta?\"}\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"En serio que como me caga que mi novio haga las cosas y no me las cuente, me las oculte.\"}\n",
      "{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Entiendo que te sientas frustrada cuando alguien oculta cosas importantes. ¿Puedes compartir más sobre lo que está pasando?\"}\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Es que siento que no confía en mí para contármelo, y eso me hace sentir excluida.\"}\n",
      "\n",
      "### Response:\n",
      " Entiendo que te sientas frustrada cuando alguien oculta cosas importantes. Es importante establecer comunicación abierta y honestidad en una relación. ¿Has intentado hablar con tu novio sobre cómo te sientes? Estoy aquí para escucharte.\n"
     ]
    }
   ],
   "source": [
    "input=inputs[2]\n",
    "prompt = f'''Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "\n",
    "### Instruction:\n",
    "{instructions[2]}\\nskip emojis.\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:'''\n",
    "a=response(prompt,100)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a454889-6cc2-4acd-8727-dca375819947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T03:16:30.197590Z",
     "iopub.status.busy": "2023-12-04T03:16:30.196943Z",
     "iopub.status.idle": "2023-12-04T03:16:32.300874Z",
     "shell.execute_reply": "2023-12-04T03:16:32.300116Z",
     "shell.execute_reply.started": "2023-12-04T03:16:30.197530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de tokens de entrada:409\n",
      "\n",
      "Salida:\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. \n",
      "\n",
      "### Instruction:\n",
      "You are an emotional assistant, respond empathetically in Spanish to each of the messages. If the user seems sad or upset, you should offer words of encouragement. If the user seems happy or excited, the assistant should share that joy and respond enthusiastically. In all cases, the assistant should maintain a respectful tone, if possible, encouraging you to talk more about it. Don't say hello, unless necessary. Use the username and pronoun to respond in a personalized way.\n",
      "skip emojis.\n",
      "\n",
      "### Input:\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Hola, me siento molesta el dio de hoy.\"}\n",
      "{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Hola Jannette, que mal que el dia de hoy no te sientas bien, ¿Podrias contarme que es lo que te molesta?\"}\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"En serio que como me caga que mi novio haga las cosas y no me las cuente, me las oculte.\"}\n",
      "{\"usuario\":\"Asistente Emocional\",\"Pronombre\":\"Él\",\"Mensaje\":\"Entiendo que te sientas frustrada cuando alguien oculta cosas importantes. ¿Puedes compartir más sobre lo que está pasando?\"}\n",
      "{\"usuario\":\"Jannette\",\"Pronombre\":\"Ella\",\"Mensaje\":\"Es que siento que no confía en mí para contármelo, y eso me hace sentir excluida.\"}\n",
      "\n",
      "### Response:\n",
      " Entiendo que te sientas frustrada cuando alguien oculta cosas importantes. La comunicación abierta y honesta es esencial para construir una relación saludable. ¿Quieres hablar más sobre lo que está sucediendo?\n"
     ]
    }
   ],
   "source": [
    "input=inputs[2]\n",
    "prompt = f'''Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "\n",
    "### Instruction:\n",
    "{instructions[2]}\\nskip emojis.\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:'''\n",
    "a=response(prompt,100)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484531c5-48cf-46e9-9534-bae8212e6a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T03:16:50.501827Z",
     "iopub.status.busy": "2023-12-04T03:16:50.500777Z",
     "iopub.status.idle": "2023-12-04T03:37:12.849884Z",
     "shell.execute_reply": "2023-12-04T03:37:12.849381Z",
     "shell.execute_reply.started": "2023-12-04T03:16:50.501802Z"
    }
   },
   "outputs": [],
   "source": [
    "final.push_to_hub(\"Just_HEAR_Me\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
